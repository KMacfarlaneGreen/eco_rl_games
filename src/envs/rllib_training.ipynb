{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a64106c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-10T09:58:53.620407Z",
     "start_time": "2023-02-10T09:58:49.254465Z"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8611f491",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T14:51:17.221850Z",
     "start_time": "2023-02-09T14:51:17.196211Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!time python train_centralised.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "731fe685",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-10T10:01:58.450207Z",
     "start_time": "2023-02-10T10:01:25.081313Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-10 10:01:38,360\tINFO worker.py:1529 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m 2023-02-10 10:01:48,720\tWARNING algorithm_config.py:488 -- Cannot create ApexDDPGConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m 2023-02-10 10:01:49,375\tINFO algorithm.py:501 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m 2023-02-10 10:01:54,446\tERROR actor_manager.py:486 -- Ray error, taking actor 1 out of service. The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=30910, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7f9ee8a44790>)\n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m   File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 712, in __init__\n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m     self._build_policy_map(\n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m   File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1970, in _build_policy_map\n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m     self.policy_map.create_policy(\n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m   File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/policy/policy_map.py\", line 146, in create_policy\n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m     policy = create_policy_for_framework(\n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m   File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/utils/policy.py\", line 126, in create_policy_for_framework\n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m     return policy_class(observation_space, action_space, merged_config)\n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m   File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/algorithms/ddpg/ddpg_torch_policy.py\", line 83, in __init__\n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m     validate_spaces(self, observation_space, action_space)\n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m   File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/algorithms/ddpg/utils.py\", line 75, in validate_spaces\n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m     raise UnsupportedSpaceException(\n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m ray.rllib.utils.error.UnsupportedSpaceException: Action space (Box(-1.0, 1.0, (2,), float32)) of DDPGTorchPolicy is not supported for DDPG.\n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m 2023-02-10 10:01:54,446\tERROR actor_manager.py:486 -- Ray error, taking actor 2 out of service. The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=30911, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7f93c0a457c0>)\n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m   File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 712, in __init__\n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m     self._build_policy_map(\n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m   File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1970, in _build_policy_map\n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m     self.policy_map.create_policy(\n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m   File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/policy/policy_map.py\", line 146, in create_policy\n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m     policy = create_policy_for_framework(\n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m   File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/utils/policy.py\", line 126, in create_policy_for_framework\n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m     return policy_class(observation_space, action_space, merged_config)\n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m   File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/algorithms/ddpg/ddpg_torch_policy.py\", line 83, in __init__\n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m     validate_spaces(self, observation_space, action_space)\n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m   File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/algorithms/ddpg/utils.py\", line 75, in validate_spaces\n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m     raise UnsupportedSpaceException(\n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m ray.rllib.utils.error.UnsupportedSpaceException: Action space (Box(-1.0, 1.0, (2,), float32)) of DDPGTorchPolicy is not supported for DDPG.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=30910)\u001b[0m 2023-02-10 10:01:54,394\tWARNING env.py:51 -- Skipping env checking for this experiment\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=30910)\u001b[0m 2023-02-10 10:01:54,436\tERROR worker.py:763 -- Exception raised in creation task: The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=30910, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7f9ee8a44790>)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=30910)\u001b[0m   File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 712, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=30910)\u001b[0m     self._build_policy_map(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=30910)\u001b[0m   File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1970, in _build_policy_map\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=30910)\u001b[0m     self.policy_map.create_policy(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=30910)\u001b[0m   File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/policy/policy_map.py\", line 146, in create_policy\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=30910)\u001b[0m     policy = create_policy_for_framework(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=30910)\u001b[0m   File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/utils/policy.py\", line 126, in create_policy_for_framework\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=30910)\u001b[0m     return policy_class(observation_space, action_space, merged_config)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=30910)\u001b[0m   File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/algorithms/ddpg/ddpg_torch_policy.py\", line 83, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=30910)\u001b[0m     validate_spaces(self, observation_space, action_space)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=30910)\u001b[0m   File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/algorithms/ddpg/utils.py\", line 75, in validate_spaces\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=30910)\u001b[0m     raise UnsupportedSpaceException(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=30910)\u001b[0m ray.rllib.utils.error.UnsupportedSpaceException: Action space (Box(-1.0, 1.0, (2,), float32)) of DDPGTorchPolicy is not supported for DDPG.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=30911)\u001b[0m 2023-02-10 10:01:54,436\tERROR worker.py:763 -- Exception raised in creation task: The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=30911, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7f93c0a457c0>)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=30911)\u001b[0m   File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 712, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=30911)\u001b[0m     self._build_policy_map(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=30911)\u001b[0m   File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1970, in _build_policy_map\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=30911)\u001b[0m     self.policy_map.create_policy(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=30911)\u001b[0m   File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/policy/policy_map.py\", line 146, in create_policy\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=30911)\u001b[0m     policy = create_policy_for_framework(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=30911)\u001b[0m   File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/utils/policy.py\", line 126, in create_policy_for_framework\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=30911)\u001b[0m     return policy_class(observation_space, action_space, merged_config)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=30911)\u001b[0m   File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/algorithms/ddpg/ddpg_torch_policy.py\", line 83, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=30911)\u001b[0m     validate_spaces(self, observation_space, action_space)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=30911)\u001b[0m   File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/algorithms/ddpg/utils.py\", line 75, in validate_spaces\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=30911)\u001b[0m     raise UnsupportedSpaceException(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=30911)\u001b[0m ray.rllib.utils.error.UnsupportedSpaceException: Action space (Box(-1.0, 1.0, (2,), float32)) of DDPGTorchPolicy is not supported for DDPG.\n",
      "== Status ==\n",
      "Current time: 2023-02-10 10:01:54 (running for 00:00:12.62)\n",
      "Memory usage on this node: 6.1/8.0 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7.0/8 CPUs, 0/0 GPUs, 0.0/2.28 GiB heap, 0.0/1.14 GiB objects\n",
      "Result logdir: /Users/Katie/ray_results/APEX_DDPG\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+----------------------------------+----------+-------+\n",
      "| Trial name                       | status   | loc   |\n",
      "|----------------------------------+----------+-------|\n",
      "| APEX_DDPG_waterworld_eadb0_00000 | RUNNING  |       |\n",
      "+----------------------------------+----------+-------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-10 10:01:54,555\tERROR trial_runner.py:1088 -- Trial APEX_DDPG_waterworld_eadb0_00000: Error processing event.\r\n",
      "ray.tune.error._TuneNoNextExecutorEventError: Traceback (most recent call last):\r\n",
      "  File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/tune/execution/ray_trial_executor.py\", line 1070, in get_next_executor_event\r\n",
      "    future_result = ray.get(ready_future)\r\n",
      "  File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\r\n",
      "    return func(*args, **kwargs)\r\n",
      "  File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/_private/worker.py\", line 2311, in get\r\n",
      "    raise value\r\n",
      "ray.exceptions.RayActorError: The actor died because of an error raised in its creation task, \u001b[36mray::ApexDDPG.__init__()\u001b[39m (pid=30901, ip=127.0.0.1, repr=ApexDDPG)\r\n",
      "  File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/evaluation/worker_set.py\", line 239, in _setup\r\n",
      "    self.add_workers(\r\n",
      "  File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/evaluation/worker_set.py\", line 612, in add_workers\r\n",
      "    raise result.get()\r\n",
      "  File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/utils/actor_manager.py\", line 473, in __fetch_result\r\n",
      "    result = ray.get(r)\r\n",
      "ray.exceptions.RayActorError: The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=30910, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7f9ee8a44790>)\r\n",
      "  File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 712, in __init__\r\n",
      "    self._build_policy_map(\r\n",
      "  File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1970, in _build_policy_map\r\n",
      "    self.policy_map.create_policy(\r\n",
      "  File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/policy/policy_map.py\", line 146, in create_policy\r\n",
      "    policy = create_policy_for_framework(\r\n",
      "  File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/utils/policy.py\", line 126, in create_policy_for_framework\r\n",
      "    return policy_class(observation_space, action_space, merged_config)\r\n",
      "  File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/algorithms/ddpg/ddpg_torch_policy.py\", line 83, in __init__\r\n",
      "    validate_spaces(self, observation_space, action_space)\r\n",
      "  File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/algorithms/ddpg/utils.py\", line 75, in validate_spaces\r\n",
      "    raise UnsupportedSpaceException(\r\n",
      "ray.rllib.utils.error.UnsupportedSpaceException: Action space (Box(-1.0, 1.0, (2,), float32)) of DDPGTorchPolicy is not supported for DDPG.\r\n",
      "\r\n",
      "During handling of the above exception, another exception occurred:\r\n",
      "\r\n",
      "\u001b[36mray::ApexDDPG.__init__()\u001b[39m (pid=30901, ip=127.0.0.1, repr=ApexDDPG)\r\n",
      "  File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/algorithms/algorithm.py\", line 441, in __init__\r\n",
      "    super().__init__(\r\n",
      "  File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/tune/trainable/trainable.py\", line 169, in __init__\r\n",
      "    self.setup(copy.deepcopy(self.config))\r\n",
      "  File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/algorithms/apex_ddpg/apex_ddpg.py\", line 145, in setup\r\n",
      "    return ApexDQN.setup(self, config)\r\n",
      "  File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/algorithms/apex_dqn/apex_dqn.py\", line 316, in setup\r\n",
      "    super().setup(config)\r\n",
      "  File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/algorithms/algorithm.py\", line 566, in setup\r\n",
      "    self.workers = WorkerSet(\r\n",
      "  File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/evaluation/worker_set.py\", line 191, in __init__\r\n",
      "    raise e.args[0].args[2]\r\n",
      "ray.rllib.utils.error.UnsupportedSpaceException: Action space (Box(-1.0, 1.0, (2,), float32)) of DDPGTorchPolicy is not supported for DDPG.\r\n",
      "\r\n",
      "Result for APEX_DDPG_waterworld_eadb0_00000:\r\n",
      "  trial_id: eadb0_00000\r\n",
      "  \r\n",
      "== Status ==\r\n",
      "Current time: 2023-02-10 10:01:54 (running for 00:00:12.68)\r\n",
      "Memory usage on this node: 6.1/8.0 GiB \r\n",
      "Using FIFO scheduling algorithm.\r\n",
      "Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/2.28 GiB heap, 0.0/1.14 GiB objects\r\n",
      "Result logdir: /Users/Katie/ray_results/APEX_DDPG\r\n",
      "Number of trials: 1/1 (1 ERROR)\r\n",
      "+----------------------------------+----------+-------+\r\n",
      "| Trial name                       | status   | loc   |\r\n",
      "|----------------------------------+----------+-------|\r\n",
      "| APEX_DDPG_waterworld_eadb0_00000 | ERROR    |       |\r\n",
      "+----------------------------------+----------+-------+\r\n",
      "Number of errored trials: 1\r\n",
      "+----------------------------------+--------------+-----------------------------------------------------------------------------------------------------+\r\n",
      "| Trial name                       |   # failures | error file                                                                                          |\r\n",
      "|----------------------------------+--------------+-----------------------------------------------------------------------------------------------------|\r\n",
      "| APEX_DDPG_waterworld_eadb0_00000 |            1 | /Users/Katie/ray_results/APEX_DDPG/APEX_DDPG_waterworld_eadb0_00000_0_2023-02-10_10-01-42/error.txt |\r\n",
      "+----------------------------------+--------------+-----------------------------------------------------------------------------------------------------+\r\n",
      "\r\n",
      "== Status ==\r\n",
      "Current time: 2023-02-10 10:01:54 (running for 00:00:12.68)\r\n",
      "Memory usage on this node: 6.1/8.0 GiB \r\n",
      "Using FIFO scheduling algorithm.\r\n",
      "Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/2.28 GiB heap, 0.0/1.14 GiB objects\r\n",
      "Result logdir: /Users/Katie/ray_results/APEX_DDPG\r\n",
      "Number of trials: 1/1 (1 ERROR)\r\n",
      "+----------------------------------+----------+-------+\r\n",
      "| Trial name                       | status   | loc   |\r\n",
      "|----------------------------------+----------+-------|\r\n",
      "| APEX_DDPG_waterworld_eadb0_00000 | ERROR    |       |\r\n",
      "+----------------------------------+----------+-------+\r\n",
      "Number of errored trials: 1\r\n",
      "+----------------------------------+--------------+-----------------------------------------------------------------------------------------------------+\r\n",
      "| Trial name                       |   # failures | error file                                                                                          |\r\n",
      "|----------------------------------+--------------+-----------------------------------------------------------------------------------------------------|\r\n",
      "| APEX_DDPG_waterworld_eadb0_00000 |            1 | /Users/Katie/ray_results/APEX_DDPG/APEX_DDPG_waterworld_eadb0_00000_0_2023-02-10_10-01-42/error.txt |\r\n",
      "+----------------------------------+--------------+-----------------------------------------------------------------------------------------------------+\r\n",
      "\r\n",
      "2023-02-10 10:01:54,565\tERROR ray_trial_executor.py:118 -- An exception occurred when trying to stop the Ray actor:Traceback (most recent call last):\r\n",
      "  File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/tune/execution/ray_trial_executor.py\", line 109, in _post_stop_cleanup\r\n",
      "    ray.get(future, timeout=timeout)\r\n",
      "  File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\r\n",
      "    return func(*args, **kwargs)\r\n",
      "  File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/_private/worker.py\", line 2311, in get\r\n",
      "    raise value\r\n",
      "ray.exceptions.RayActorError: The actor died because of an error raised in its creation task, \u001b[36mray::ApexDDPG.__init__()\u001b[39m (pid=30901, ip=127.0.0.1, repr=ApexDDPG)\r\n",
      "  File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/evaluation/worker_set.py\", line 239, in _setup\r\n",
      "    self.add_workers(\r\n",
      "  File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/evaluation/worker_set.py\", line 612, in add_workers\r\n",
      "    raise result.get()\r\n",
      "  File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/utils/actor_manager.py\", line 473, in __fetch_result\r\n",
      "    result = ray.get(r)\r\n",
      "ray.exceptions.RayActorError: The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=30910, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7f9ee8a44790>)\r\n",
      "  File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 712, in __init__\r\n",
      "    self._build_policy_map(\r\n",
      "  File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1970, in _build_policy_map\r\n",
      "    self.policy_map.create_policy(\r\n",
      "  File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/policy/policy_map.py\", line 146, in create_policy\r\n",
      "    policy = create_policy_for_framework(\r\n",
      "  File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/utils/policy.py\", line 126, in create_policy_for_framework\r\n",
      "    return policy_class(observation_space, action_space, merged_config)\r\n",
      "  File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/algorithms/ddpg/ddpg_torch_policy.py\", line 83, in __init__\r\n",
      "    validate_spaces(self, observation_space, action_space)\r\n",
      "  File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/algorithms/ddpg/utils.py\", line 75, in validate_spaces\r\n",
      "    raise UnsupportedSpaceException(\r\n",
      "ray.rllib.utils.error.UnsupportedSpaceException: Action space (Box(-1.0, 1.0, (2,), float32)) of DDPGTorchPolicy is not supported for DDPG.\r\n",
      "\r\n",
      "During handling of the above exception, another exception occurred:\r\n",
      "\r\n",
      "\u001b[36mray::ApexDDPG.__init__()\u001b[39m (pid=30901, ip=127.0.0.1, repr=ApexDDPG)\r\n",
      "  File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/algorithms/algorithm.py\", line 441, in __init__\r\n",
      "    super().__init__(\r\n",
      "  File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/tune/trainable/trainable.py\", line 169, in __init__\r\n",
      "    self.setup(copy.deepcopy(self.config))\r\n",
      "  File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/algorithms/apex_ddpg/apex_ddpg.py\", line 145, in setup\r\n",
      "    return ApexDQN.setup(self, config)\r\n",
      "  File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/algorithms/apex_dqn/apex_dqn.py\", line 316, in setup\r\n",
      "    super().setup(config)\r\n",
      "  File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/algorithms/algorithm.py\", line 566, in setup\r\n",
      "    self.workers = WorkerSet(\r\n",
      "  File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/evaluation/worker_set.py\", line 191, in __init__\r\n",
      "    raise e.args[0].args[2]\r\n",
      "ray.rllib.utils.error.UnsupportedSpaceException: Action space (Box(-1.0, 1.0, (2,), float32)) of DDPGTorchPolicy is not supported for DDPG.\r\n",
      "\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m 2023-02-10 10:01:54,501\tERROR worker.py:763 -- Exception raised in creation task: The actor died because of an error raised in its creation task, \u001b[36mray::ApexDDPG.__init__()\u001b[39m (pid=30901, ip=127.0.0.1, repr=ApexDDPG)\n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m   File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/evaluation/worker_set.py\", line 239, in _setup\n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m     self.add_workers(\n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m   File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/evaluation/worker_set.py\", line 612, in add_workers\n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m     raise result.get()\n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m   File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/utils/actor_manager.py\", line 473, in __fetch_result\n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m     result = ray.get(r)\n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m ray.exceptions.RayActorError: The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=30910, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7f9ee8a44790>)\n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m   File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 712, in __init__\n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m     self._build_policy_map(\n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m   File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1970, in _build_policy_map\n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m     self.policy_map.create_policy(\n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m   File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/policy/policy_map.py\", line 146, in create_policy\n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m     policy = create_policy_for_framework(\n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m   File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/utils/policy.py\", line 126, in create_policy_for_framework\n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m     return policy_class(observation_space, action_space, merged_config)\n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m   File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/algorithms/ddpg/ddpg_torch_policy.py\", line 83, in __init__\n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m     validate_spaces(self, observation_space, action_space)\n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m   File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/algorithms/ddpg/utils.py\", line 75, in validate_spaces\n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m     raise UnsupportedSpaceException(\n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m ray.rllib.utils.error.UnsupportedSpaceException: Action space (Box(-1.0, 1.0, (2,), float32)) of DDPGTorchPolicy is not supported for DDPG.\n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m \n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m \n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m \u001b[36mray::ApexDDPG.__init__()\u001b[39m (pid=30901, ip=127.0.0.1, repr=ApexDDPG)\n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m   File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/algorithms/algorithm.py\", line 441, in __init__\n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m     super().__init__(\n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m   File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/tune/trainable/trainable.py\", line 169, in __init__\n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m     self.setup(copy.deepcopy(self.config))\n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m   File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/algorithms/apex_ddpg/apex_ddpg.py\", line 145, in setup\n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m     return ApexDQN.setup(self, config)\n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m   File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/algorithms/apex_dqn/apex_dqn.py\", line 316, in setup\n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m     super().setup(config)\n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m   File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/algorithms/algorithm.py\", line 566, in setup\n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m     self.workers = WorkerSet(\n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m   File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/evaluation/worker_set.py\", line 191, in __init__\n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m     raise e.args[0].args[2]\n",
      "\u001b[2m\u001b[36m(ApexDDPG pid=30901)\u001b[0m ray.rllib.utils.error.UnsupportedSpaceException: Action space (Box(-1.0, 1.0, (2,), float32)) of DDPGTorchPolicy is not supported for DDPG.\n",
      "2023-02-10 10:01:54,675\tERROR tune.py:758 -- Trials did not complete: [APEX_DDPG_waterworld_eadb0_00000]\n",
      "2023-02-10 10:01:54,675\tINFO tune.py:762 -- Total run time: 12.94 seconds (12.68 seconds for the tuning loop).\n",
      "\u001b[0mpython rllib_test.py  10.08s user 3.62s system 41% cpu 32.721 total\n"
     ]
    }
   ],
   "source": [
    "!time python rllib_test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a0a488b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T14:51:58.989851Z",
     "start_time": "2023-02-09T14:51:53.981659Z"
    }
   },
   "outputs": [],
   "source": [
    "from gymnasium.spaces import Box, Discrete\n",
    "from ray import air, tune\n",
    "from ray.rllib.algorithms.algorithm_config import AlgorithmConfig\n",
    "from ray.rllib.algorithms.dqn import DQNConfig\n",
    "from ray.rllib.env import PettingZooEnv\n",
    "from ray.rllib.env.wrappers.pettingzoo_env import ParallelPettingZooEnv\n",
    "from ray.rllib.policy.policy import PolicySpec\n",
    "from ray.rllib.utils.framework import try_import_tf, try_import_torch\n",
    "from ray.rllib.utils.test_utils import check_learning_achieved\n",
    "from ray.tune.registry import register_env\n",
    "from src.envs import antisocial_ring_v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0ea65130",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T14:53:56.662337Z",
     "start_time": "2023-02-09T14:53:56.631259Z"
    }
   },
   "outputs": [],
   "source": [
    "from ray.tune.logger import pretty_print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "244fd3b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T14:56:53.166475Z",
     "start_time": "2023-02-09T14:56:53.025308Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': array([1., 1., 0.]), '1': array([1., 1., 0.]), '2': array([0., 1., 0.]), '3': array([0., 1., 1.]), '4': array([0., 1., 1.])}\n",
      "Discrete(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/gymnasium/spaces/box.py:129: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  gym.logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n"
     ]
    }
   ],
   "source": [
    "env = ParallelPettingZooEnv(antisocial_ring_v0.parallel_env())\n",
    "print(env.reset())\n",
    "print(env.action_space)\n",
    "env_name = \"AntisocialRing\"\n",
    "register_env(env_name, lambda config: ParallelPettingZooEnv(antisocial_ring_v0.parallel_env()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5b51ece8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T15:11:58.856918Z",
     "start_time": "2023-02-09T15:11:58.850734Z"
    }
   },
   "outputs": [],
   "source": [
    "from ray.rllib.env import PettingZooEnv\n",
    "from pettingzoo.classic import rps_v2\n",
    "from ray.rllib.algorithms.pg import (\n",
    "    PG,\n",
    "    PGConfig,\n",
    "    PGTF2Policy,\n",
    "    PGTF1Policy,\n",
    "    PGTorchPolicy,\n",
    ")\n",
    "from ray.rllib.utils.test_utils import check_learning_achieved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a28c2b15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T15:16:00.963291Z",
     "start_time": "2023-02-09T15:15:58.330135Z"
    }
   },
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2f933040",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T15:16:33.515843Z",
     "start_time": "2023-02-09T15:16:00.984897Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-02-09 15:16:33</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:19.07        </td></tr>\n",
       "<tr><td>Memory:      </td><td>6.2/8.0 GiB        </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  \n",
       "  \n",
       "  Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PG_RockPaperScissors_b1569_00000</td><td style=\"text-align: right;\">           1</td><td>/Users/Katie/ray_results/PG/PG_RockPaperScissors_b1569_00000_0_2023-02-09_15-16-15/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PG_RockPaperScissors_b1569_00000</td><td>ERROR   </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(PG pid=27168)\u001b[0m 2023-02-09 15:16:30,965\tWARNING algorithm_config.py:488 -- Cannot create PGConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(PG pid=27168)\u001b[0m 2023-02-09 15:16:33,133\tINFO algorithm.py:501 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(PG pid=27168)\u001b[0m 2023-02-09 15:16:33,137\tWARNING env.py:51 -- Skipping env checking for this experiment\n",
      "\u001b[2m\u001b[36m(PG pid=27168)\u001b[0m 2023-02-09 15:16:33,182\tERROR worker.py:763 -- Exception raised in creation task: The actor died because of an error raised in its creation task, \u001b[36mray::PG.__init__()\u001b[39m (pid=27168, ip=127.0.0.1, repr=PG)\n",
      "\u001b[2m\u001b[36m(PG pid=27168)\u001b[0m   File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/algorithms/algorithm.py\", line 441, in __init__\n",
      "\u001b[2m\u001b[36m(PG pid=27168)\u001b[0m     super().__init__(\n",
      "\u001b[2m\u001b[36m(PG pid=27168)\u001b[0m   File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/tune/trainable/trainable.py\", line 169, in __init__\n",
      "\u001b[2m\u001b[36m(PG pid=27168)\u001b[0m     self.setup(copy.deepcopy(self.config))\n",
      "\u001b[2m\u001b[36m(PG pid=27168)\u001b[0m   File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/algorithms/algorithm.py\", line 566, in setup\n",
      "\u001b[2m\u001b[36m(PG pid=27168)\u001b[0m     self.workers = WorkerSet(\n",
      "\u001b[2m\u001b[36m(PG pid=27168)\u001b[0m   File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/evaluation/worker_set.py\", line 169, in __init__\n",
      "\u001b[2m\u001b[36m(PG pid=27168)\u001b[0m     self._setup(\n",
      "\u001b[2m\u001b[36m(PG pid=27168)\u001b[0m   File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/evaluation/worker_set.py\", line 259, in _setup\n",
      "\u001b[2m\u001b[36m(PG pid=27168)\u001b[0m     self._local_worker = self._make_worker(\n",
      "\u001b[2m\u001b[36m(PG pid=27168)\u001b[0m   File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/evaluation/worker_set.py\", line 941, in _make_worker\n",
      "\u001b[2m\u001b[36m(PG pid=27168)\u001b[0m     worker = cls(\n",
      "\u001b[2m\u001b[36m(PG pid=27168)\u001b[0m   File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 662, in __init__\n",
      "\u001b[2m\u001b[36m(PG pid=27168)\u001b[0m     self.policy_dict, self.is_policy_to_train = self.config.get_multi_agent_setup(\n",
      "\u001b[2m\u001b[36m(PG pid=27168)\u001b[0m   File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/algorithms/algorithm_config.py\", line 2182, in get_multi_agent_setup\n",
      "\u001b[2m\u001b[36m(PG pid=27168)\u001b[0m     raise ValueError(\n",
      "\u001b[2m\u001b[36m(PG pid=27168)\u001b[0m ValueError: `observation_space` not provided in PolicySpec for default_policy and env does not have an observation space OR no spaces received from other workers' env(s) OR no `observation_space` specified in config!\n",
      "2023-02-09 15:16:33,302\tERROR trial_runner.py:1088 -- Trial PG_RockPaperScissors_b1569_00000: Error processing event.\n",
      "ray.tune.error._TuneNoNextExecutorEventError: Traceback (most recent call last):\n",
      "  File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/tune/execution/ray_trial_executor.py\", line 1070, in get_next_executor_event\n",
      "    future_result = ray.get(ready_future)\n",
      "  File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/_private/worker.py\", line 2311, in get\n",
      "    raise value\n",
      "ray.exceptions.RayActorError: The actor died because of an error raised in its creation task, \u001b[36mray::PG.__init__()\u001b[39m (pid=27168, ip=127.0.0.1, repr=PG)\n",
      "  File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/algorithms/algorithm.py\", line 441, in __init__\n",
      "    super().__init__(\n",
      "  File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/tune/trainable/trainable.py\", line 169, in __init__\n",
      "    self.setup(copy.deepcopy(self.config))\n",
      "  File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/algorithms/algorithm.py\", line 566, in setup\n",
      "    self.workers = WorkerSet(\n",
      "  File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/evaluation/worker_set.py\", line 169, in __init__\n",
      "    self._setup(\n",
      "  File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/evaluation/worker_set.py\", line 259, in _setup\n",
      "    self._local_worker = self._make_worker(\n",
      "  File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/evaluation/worker_set.py\", line 941, in _make_worker\n",
      "    worker = cls(\n",
      "  File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 662, in __init__\n",
      "    self.policy_dict, self.is_policy_to_train = self.config.get_multi_agent_setup(\n",
      "  File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/algorithms/algorithm_config.py\", line 2182, in get_multi_agent_setup\n",
      "    raise ValueError(\n",
      "ValueError: `observation_space` not provided in PolicySpec for default_policy and env does not have an observation space OR no spaces received from other workers' env(s) OR no `observation_space` specified in config!\n",
      "\n",
      "2023-02-09 15:16:33,349\tERROR ray_trial_executor.py:118 -- An exception occurred when trying to stop the Ray actor:Traceback (most recent call last):\n",
      "  File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/tune/execution/ray_trial_executor.py\", line 109, in _post_stop_cleanup\n",
      "    ray.get(future, timeout=timeout)\n",
      "  File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/_private/worker.py\", line 2311, in get\n",
      "    raise value\n",
      "ray.exceptions.RayActorError: The actor died because of an error raised in its creation task, \u001b[36mray::PG.__init__()\u001b[39m (pid=27168, ip=127.0.0.1, repr=PG)\n",
      "  File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/algorithms/algorithm.py\", line 441, in __init__\n",
      "    super().__init__(\n",
      "  File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/tune/trainable/trainable.py\", line 169, in __init__\n",
      "    self.setup(copy.deepcopy(self.config))\n",
      "  File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/algorithms/algorithm.py\", line 566, in setup\n",
      "    self.workers = WorkerSet(\n",
      "  File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/evaluation/worker_set.py\", line 169, in __init__\n",
      "    self._setup(\n",
      "  File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/evaluation/worker_set.py\", line 259, in _setup\n",
      "    self._local_worker = self._make_worker(\n",
      "  File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/evaluation/worker_set.py\", line 941, in _make_worker\n",
      "    worker = cls(\n",
      "  File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 662, in __init__\n",
      "    self.policy_dict, self.is_policy_to_train = self.config.get_multi_agent_setup(\n",
      "  File \"/Users/Katie/code/eco_rl_games/env/lib/python3.8/site-packages/ray/rllib/algorithms/algorithm_config.py\", line 2182, in get_multi_agent_setup\n",
      "    raise ValueError(\n",
      "ValueError: `observation_space` not provided in PolicySpec for default_policy and env does not have an observation space OR no spaces received from other workers' env(s) OR no `observation_space` specified in config!\n",
      "\n",
      "2023-02-09 15:16:33,458\tERROR tune.py:758 -- Trials did not complete: [PG_RockPaperScissors_b1569_00000]\n",
      "2023-02-09 15:16:33,461\tINFO tune.py:762 -- Total run time: 19.22 seconds (19.07 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "def env_creator(args):\n",
    "    env = rps_v2.env()\n",
    "    return env\n",
    "\n",
    "\n",
    "register_env(\"RockPaperScissors\", lambda config: PettingZooEnv(env_creator(config)))\n",
    "\n",
    "ray.init()\n",
    "\n",
    "stop = {\n",
    "        \"training_iteration\": 150,\n",
    "        \"timesteps_total\": 100,\n",
    "        \"episode_reward_mean\": 100,\n",
    "    }\n",
    "\n",
    "config = PGConfig().environment(\"RockPaperScissors\").framework('torch')\n",
    "\n",
    "results = tune.Tuner(\n",
    "     \"PG\", param_space=config, run_config=air.RunConfig(stop=stop, verbose=1)).fit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f94a1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5085312e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
