{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dc07e15",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-09-20T14:49:24.979Z"
    }
   },
   "outputs": [],
   "source": [
    "#from ring_environment import Environment\n",
    "import os\n",
    "import gzip\n",
    "import math\n",
    "import copy\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "from multiprocessing import Queue, Lock\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "from agent import Agent\n",
    "from mind import Mind\n",
    "from ring_environment import Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "793fb319",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 130)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m<tokenize>:130\u001b[0;36m\u001b[0m\n\u001b[0;31m    else:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "class Environment:\n",
    "    def __init__(self, size, num_actions = 2, name = None, \n",
    "            max_iteration = 5000, num_agents = 20):\n",
    "       \n",
    "        node_num = self.size = size\n",
    "        self.graph = nx.cycle_graph(node_num)\n",
    "        self.nodes = list(self.graph.nodes)\n",
    "        self.num_agents = num_agents\n",
    "        input_size = 1\n",
    "        self.mind = Mind(input_size, num_actions)\n",
    "\n",
    "        #to do: sort mind function:\n",
    "        #- inputs, outputs, handling each agent's individual mind\n",
    "\n",
    "        #self.A_mind = Mind(input_size, num_actions, self.lock, Queue())\n",
    "        #self.B_mind = Mind(input_size, num_actions, self.lock, Queue())\n",
    "        #for segregation the agent_range defines the window that each agent can observe which is then input to that nn\n",
    "        self.max_iteration = max_iteration\n",
    "\n",
    "        #self.vals = [-1, 0, 1, 2]  #possible values for grid squares in segregation case\n",
    "        #self.names_to_vals = {\"void\": -2, \"A\": -1, \"free\": 0, \"B\": 1, \"prey\": 2}\n",
    "        #self.vals_to_names = {v: k for k, v in self.names_to_vals.items()}\n",
    "        #self.vals_to_index = {-1: 0, 0: 1, 1: 2, 2: 3}\n",
    "\n",
    "        self.crystal = np.zeros((max_iteration, node_num, 1))  #id  -should there be other info in this?\n",
    "        #what actually is this crystal object? Is this what's being saved?\n",
    "\n",
    "        self.history = []        #think about what quantities I want to save\n",
    "        self.id_track = []       #how to define, intitialise and store them \n",
    "        self.records = []\n",
    "\n",
    "        if name:\n",
    "            self.name = name\n",
    "\n",
    "        if not os.path.isdir(str(self.name)):\n",
    "            #os.mkdir(str(self.name))\n",
    "            #os.mkdir(str(self.name)+'/episodes')\n",
    "            self.map, self.agents, self.loc_to_agent, self.id_to_agent = self._generate_map()\n",
    "            #self._set_initial_states()\n",
    "            #self.mask = self._get_mask()\n",
    "            #self.crystal = np.zeros((max_iteration, nodes, 2)) # tr,  id\n",
    "            #self.iteration = 0\n",
    "        else:\n",
    "            assert False, \"There exists an experiment with this name.\"\n",
    "\n",
    "\n",
    "\n",
    "    def _generate_map(self):\n",
    "        #generates representation of environment in a given state\n",
    "        #rewrite this function to give graph with a given number of agents on each node\n",
    "        #where:\n",
    "        # map = graph with n agents on each node (state of environment)\n",
    "        # agents = agents\n",
    "        # loc_to_agent = location of each agent   what is the structure of these dicionaries? \n",
    "        # id_to_agent = id of each agent\n",
    "        # work out how to include mind networks\n",
    "        map = np.zeros(self.size)   #index corresponds to graph node i.e. map[0] = 1 means there is one agent on node zero\n",
    "        loc_to_agent = {}\n",
    "        id_to_agent = {}\n",
    "        agents = []\n",
    "        idx = 0\n",
    "        init_nodes = np.zeros(self.num_agents) #initialise agent locations (gives initial node loaction for each agent i.e. init_node[0] = 10 means agent 0 begins on node 10) \n",
    "        for j in range(0, self.num_agents):   #needs to be outside loop over nodes so doesn't change each time\n",
    "            init_nodes[j] = np.random.choice(self.nodes)\n",
    "            mind = self.mind\n",
    "            agent = Agent(idx, (init_nodes[j]),mind)\n",
    "            loc_to_agent[(init_nodes[j])] = agent\n",
    "            id_to_agent[idx] = agent\n",
    "            agents.append(agent)\n",
    "            idx += 1\n",
    "\n",
    "        for i in enumerate(map):\n",
    "            #print(i)\n",
    "            for x in range(0, self.num_agents):\n",
    "                #print(i[1], init_nodes[x])\n",
    "                if i[0] == init_nodes[x]:\n",
    "                    \n",
    "                    #print(int(i[1]))\n",
    "                    map[i[0]] += 1\n",
    "            \n",
    "            #val = np.random.choice(self.vals, p=self.probs)   #val = number of agents on node i\n",
    "                                                                #not a random choice - should this come after or within agent loop/assignation\n",
    "                                                                #similar structure if val not == 0?\n",
    "                                                                #how to assign number of agents to graph originally?\n",
    "\n",
    "            #map[i] = val     #this is the 'value' of the grid square in the segregation problem being added to the map\n",
    "                                    #this is what I need to change to graph nodes with given numbers of agents present\n",
    "        return map, agents, loc_to_agent, id_to_agent\n",
    "    \n",
    "    def move(self, agent):\n",
    "        #to do: convert these location coordinates to graph nodes\n",
    "        (i) = loc = agent.get_loc()     #only need single index to correspond to single node \n",
    "        (i_n) = to = agent.get_decision()  #decision returns 0 for move left and 1 for move right\n",
    "                \n",
    "        self.map[i] -= 1         #remove an agent from the previous node\n",
    "        self.map[i_n] += 1       #add this agent to the new node \n",
    "        agent.set_loc(to)         #set this new node location to the agent\n",
    "        self.loc_to_agent[to] = agent        \n",
    "        del self.loc_to_agent[loc]   #delete the previous entry in the dictionary\n",
    "        \n",
    "    def step(self, agent, act):\n",
    "         #function for calculating the local reward of each agent cumulative and global entropy reward should be calculated somewhere else - mind?\n",
    "        (i) = agent.get_loc() # current location - change to graph\n",
    "        assert self.loc_to_agent[(i)]\n",
    "        (di) = act     #action \n",
    "        (i_n) = self._add((i), (di))\n",
    "        agent.set_decision((i_n))\n",
    "        self.move(agent)\n",
    "        \n",
    "        if self.map[i_n] == 1.0:   #if agent has moved to a node where it is the only one present it receives a positive reward\n",
    "            rew = 1                     \n",
    "            assert rew != None                             \n",
    "        elif self.map[i_n] > 1.0:  #if agent moves to a node where there are also other agents then it recieves a negatibve reward\n",
    "            rew = -1\n",
    "            assert rew != None\n",
    "        else:\n",
    "            assert rew != None     #raise assertion error if node value at agent location is zero\n",
    "        done = False\n",
    "        self.update_agent(agent, rew, done)\n",
    "        agent.clear_decision()\n",
    "        return rew\n",
    "    \n",
    "    def _add(self, loc, act):\n",
    "        i = loc\n",
    "        di = act  #action (0=left, 1=right)\n",
    "        if di == 0:\n",
    "            #move left\n",
    "             if loc == 0.0:\n",
    "                (i_n) = to = 99.0\n",
    "            else:\n",
    "                (i_n) = to = loc - 1   \n",
    "        if di == 1:\n",
    "            #move right\n",
    "            if loc < 99.0:\n",
    "                (i_n) = to = loc + 1\n",
    "            else:\n",
    "                (i_n)= to = 0.0\n",
    "        return (i_n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "221b3b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43mEnvironment\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTest1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/eco_rl_games/src/ring_environment.py:56\u001b[0m, in \u001b[0;36mEnvironment.__init__\u001b[0;34m(self, size, num_actions, name, max_iteration, num_agents, lock)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)):\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;66;03m#os.mkdir(str(self.name))\u001b[39;00m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;66;03m#os.mkdir(str(self.name)+'/episodes')\u001b[39;00m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmap, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magents, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc_to_agent, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid_to_agent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_map()\n\u001b[0;32m---> 56\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_initial_states\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcrystal \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((max_iteration, node_num, \u001b[38;5;241m1\u001b[39m)) \u001b[38;5;66;03m#in segregation crystal is an array which saves the agent type, id and age at each location at each iteration\u001b[39;00m\n\u001b[1;32m     58\u001b[0m                                                           \u001b[38;5;66;03m#for me I just want to save the number of agents at each node at each iteration (map)\u001b[39;00m\n",
      "File \u001b[0;32m~/Code/eco_rl_games/src/ring_environment.py:256\u001b[0m, in \u001b[0;36mEnvironment._set_initial_states\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_initial_states\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m agent \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magents:\n\u001b[0;32m--> 256\u001b[0m         state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_agent_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m         agent\u001b[38;5;241m.\u001b[39mset_current_state(state)\n",
      "File \u001b[0;32m~/Code/eco_rl_games/src/ring_environment.py:179\u001b[0m, in \u001b[0;36mEnvironment.get_agent_state\u001b[0;34m(self, agent)\u001b[0m\n\u001b[1;32m    177\u001b[0m (i)\u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mget_loc()\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[0;32m--> 179\u001b[0m fov \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fov\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "env = Environment(100, 2, 'Test1', 5000, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "552a9a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "agent_state = env.agents[0].get_state()\n",
    "print(agent_state)\n",
    "action = env.agents[0].decide(agent_state)\n",
    "print(action)\n",
    "#print(env.move(env.agents[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac81cb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#map, agents, loc_to_agent, id_to_agent = env._generate_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a5a023d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "map [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.\n",
      " 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('map', env.map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9651939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agents 19.0\n"
     ]
    }
   ],
   "source": [
    "print('agents', env.agents[0].get_loc())   #env.agents[3].get_id() returns 3 which is correct\n",
    "\n",
    "#need to update location so that it is inputting actual agent location not the same number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a695c029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loc {19.0: <agent.Agent object at 0x7fa870f09570>, 11.0: <agent.Agent object at 0x7fa870f0bd00>, 88.0: <agent.Agent object at 0x7fa870f08220>, 61.0: <agent.Agent object at 0x7fa870f09960>, 81.0: <agent.Agent object at 0x7fa870f0ba60>, 30.0: <agent.Agent object at 0x7fa870f0b640>, 77.0: <agent.Agent object at 0x7fa870f08280>, 80.0: <agent.Agent object at 0x7fa870f08a30>, 78.0: <agent.Agent object at 0x7fa870f09d20>, 28.0: <agent.Agent object at 0x7fa870f0a800>, 40.0: <agent.Agent object at 0x7fa870f0ac80>, 24.0: <agent.Agent object at 0x7fa87152ca60>, 76.0: <agent.Agent object at 0x7fa87152c5e0>, 20.0: <agent.Agent object at 0x7fa87152c580>, 95.0: <agent.Agent object at 0x7fa87152c550>, 36.0: <agent.Agent object at 0x7fa87152c5b0>, 6.0: <agent.Agent object at 0x7fa87152c610>, 45.0: <agent.Agent object at 0x7fa87152c520>, 74.0: <agent.Agent object at 0x7fa87152c490>, 86.0: <agent.Agent object at 0x7fa87152c4f0>}\n"
     ]
    }
   ],
   "source": [
    "print('loc', env.loc_to_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74bd9a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id {0: <agent.Agent object at 0x7fa870f09570>, 1: <agent.Agent object at 0x7fa870f0bd00>, 2: <agent.Agent object at 0x7fa870f08220>, 3: <agent.Agent object at 0x7fa870f09960>, 4: <agent.Agent object at 0x7fa870f0ba60>, 5: <agent.Agent object at 0x7fa870f0b640>, 6: <agent.Agent object at 0x7fa870f08280>, 7: <agent.Agent object at 0x7fa870f08a30>, 8: <agent.Agent object at 0x7fa870f09d20>, 9: <agent.Agent object at 0x7fa870f0a800>, 10: <agent.Agent object at 0x7fa870f0ac80>, 11: <agent.Agent object at 0x7fa87152ca60>, 12: <agent.Agent object at 0x7fa87152c5e0>, 13: <agent.Agent object at 0x7fa87152c580>, 14: <agent.Agent object at 0x7fa87152c550>, 15: <agent.Agent object at 0x7fa87152c5b0>, 16: <agent.Agent object at 0x7fa87152c610>, 17: <agent.Agent object at 0x7fa87152c520>, 18: <agent.Agent object at 0x7fa87152c490>, 19: <agent.Agent object at 0x7fa87152c4f0>}\n"
     ]
    }
   ],
   "source": [
    "print('id', env.id_to_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c797b5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now know what all of these outputs are I can move onto other functions tomorrow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "905c0f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_array = np.zeros(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "700ff196",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_array[5] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6755c96c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bae7b8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
